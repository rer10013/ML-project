{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPQyg5Kj/u4e+zn3or5S3ZT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rer10013/ML-project/blob/main/Pytorch_Basic_3_3_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "du8agv3FaCYn"
      },
      "outputs": [],
      "source": [
        "# Library\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mnist dataset\n",
        "!git clone https://github.com/baek2sm/ml.git\n",
        "!tar -zxvf ./ml/datasets/MNIST.tar.gz\n",
        "\n",
        "# import datasets\n",
        "path = './'\n",
        "train_dataset = datasets.MNIST(path, train=True, download=True)\n",
        "test_dataset = datasets.MNIST(path, train=False, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vaToEfZa-44",
        "outputId": "bb9b83cf-a640-402f-8921-049734b26750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ml' already exists and is not an empty directory.\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train set\n",
        "X_train, y_train = train_dataset.data / 255, train_dataset.targets\n",
        "# test set\n",
        "X_test, y_test = test_dataset.data / 255, test_dataset.targets"
      ],
      "metadata": {
        "id": "Lc2m0UkvbluK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check data\n",
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "print(\"X_test: \", X_test.shape)\n",
        "print(\"y_test: \", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ0uFqrOcICu",
        "outputId": "90bed8da-4ab4-4b7e-b1f1-d178b19e8d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  torch.Size([60000, 28, 28])\n",
            "y_train:  torch.Size([60000])\n",
            "X_test:  torch.Size([10000, 28, 28])\n",
            "y_test:  torch.Size([10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train set 2d to 1d\n",
        "X_train = X_train.view(-1, 28 * 28)\n",
        "X_test = X_test.view(-1, 28 * 28)\n",
        "\n",
        "# check data again\n",
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"X_test: \", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yRqTxIGcM2p",
        "outputId": "ac38d52b-1cd9-4f2c-ee91-dd892a346d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  torch.Size([60000, 784])\n",
            "X_test:  torch.Size([10000, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make datasheet\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# make batch dataloader\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "xdmIcXjnckBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DNN model class\n",
        "class DNN(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super().__init__()\n",
        "        self.hidden_layer1 = nn.Sequential(\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.hidden_layer2 = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.hidden_layer3 = nn.Sequential(\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.output_layer = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self.hidden_layer1(X)\n",
        "        out = self.hidden_layer2(out)\n",
        "        out = self.hidden_layer3(out)\n",
        "        out = self.output_layer(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "qVG2e3k8dIEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check model to GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# make DNN object\n",
        "model = DNN(num_features=28*28).to(device)\n",
        "\n",
        "# make CE loss model object\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# make Adam optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "NznjE4hwd6jA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define train model\n",
        "def train(model, criterion, optimizer, loader):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # batch train\n",
        "    for X_batch, y_batch in loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X_batch)\n",
        "        loss = criterion(hypothesis, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        y_predicted = torch.argmax(hypothesis, dim=1)\n",
        "        acc = (y_predicted == y_batch).float().mean()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(loader), epoch_acc / len(loader)"
      ],
      "metadata": {
        "id": "rIQHCHKUeHI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define evaluation model\n",
        "def evaluate(model, criterion, loader):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            hypothesis = model(X_batch)\n",
        "            loss = criterion(hypothesis, y_batch)\n",
        "            y_predicted = torch.argmax(hypothesis, dim=1)\n",
        "            acc = (y_predicted == y_batch).float().mean()\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "        return epoch_loss / len(loader), epoch_acc / len(loader)"
      ],
      "metadata": {
        "id": "PT7-6BVafEyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "num_epochs = 20\n",
        "previous_train_loss, previous_train_acc = 1, 0\n",
        "previous_test_loss, previous_test_acc = 1, 0\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    current_train_loss, current_train_acc = train(model, criterion, optimizer, train_loader)\n",
        "    current_test_loss, current_test_acc = evaluate(model, criterion, test_loader)\n",
        "\n",
        "    print(f'epoch: {epoch}, train_loss: {current_train_loss:.4f}, train_acc: {current_train_acc:.4f}, test_loss: {current_test_loss:.4f}, test_acc: {current_test_acc:.4f} | {\"boolshit\" if current_train_acc + current_test_acc < previous_train_acc + previous_test_acc else \"awesome\"}')\n",
        "    previous_train_loss, previous_train_acc = current_train_loss, current_train_acc\n",
        "    previous_test_loss, previous_test_acc = current_test_loss, current_test_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQNX90tifrys",
        "outputId": "57c46f5f-012d-4887-d1c5-851e681319d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, train_loss: 0.4702, train_acc: 0.8714, test_loss: 0.2322, test_acc: 0.9332 | awesome\n",
            "epoch: 2, train_loss: 0.2010, train_acc: 0.9419, test_loss: 0.1584, test_acc: 0.9518 | awesome\n",
            "epoch: 3, train_loss: 0.1456, train_acc: 0.9573, test_loss: 0.1328, test_acc: 0.9603 | awesome\n",
            "epoch: 4, train_loss: 0.1111, train_acc: 0.9673, test_loss: 0.1033, test_acc: 0.9684 | awesome\n",
            "epoch: 5, train_loss: 0.0872, train_acc: 0.9744, test_loss: 0.0932, test_acc: 0.9710 | awesome\n",
            "epoch: 6, train_loss: 0.0692, train_acc: 0.9792, test_loss: 0.0878, test_acc: 0.9710 | awesome\n",
            "epoch: 7, train_loss: 0.0565, train_acc: 0.9832, test_loss: 0.0773, test_acc: 0.9749 | awesome\n",
            "epoch: 8, train_loss: 0.0464, train_acc: 0.9863, test_loss: 0.0760, test_acc: 0.9772 | awesome\n",
            "epoch: 9, train_loss: 0.0382, train_acc: 0.9885, test_loss: 0.0711, test_acc: 0.9775 | awesome\n",
            "epoch: 10, train_loss: 0.0306, train_acc: 0.9911, test_loss: 0.0682, test_acc: 0.9797 | awesome\n",
            "epoch: 11, train_loss: 0.0255, train_acc: 0.9923, test_loss: 0.0666, test_acc: 0.9805 | awesome\n",
            "epoch: 12, train_loss: 0.0204, train_acc: 0.9943, test_loss: 0.0699, test_acc: 0.9779 | boolshit\n",
            "epoch: 13, train_loss: 0.0159, train_acc: 0.9955, test_loss: 0.0688, test_acc: 0.9792 | awesome\n",
            "epoch: 14, train_loss: 0.0143, train_acc: 0.9959, test_loss: 0.0748, test_acc: 0.9784 | boolshit\n",
            "epoch: 15, train_loss: 0.0113, train_acc: 0.9967, test_loss: 0.0701, test_acc: 0.9811 | awesome\n",
            "epoch: 16, train_loss: 0.0094, train_acc: 0.9974, test_loss: 0.0722, test_acc: 0.9789 | boolshit\n",
            "epoch: 17, train_loss: 0.0071, train_acc: 0.9982, test_loss: 0.0733, test_acc: 0.9802 | awesome\n",
            "epoch: 18, train_loss: 0.0066, train_acc: 0.9981, test_loss: 0.0820, test_acc: 0.9789 | boolshit\n",
            "epoch: 19, train_loss: 0.0056, train_acc: 0.9984, test_loss: 0.0778, test_acc: 0.9813 | awesome\n",
            "epoch: 20, train_loss: 0.0047, train_acc: 0.9985, test_loss: 0.0963, test_acc: 0.9768 | boolshit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-3A_nEO6gB7K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}