{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNHleJaIydgVgRRypKbB5Tf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rer10013/ML-project/blob/main/Pytorch_Basic_3_4_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-woTtF7CgjBE"
      },
      "outputs": [],
      "source": [
        "# libraries\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mnist dataset\n",
        "!git clone https://github.com/baek2sm/ml.git\n",
        "!tar -zxvf ./ml/datasets/MNIST.tar.gz\n",
        "\n",
        "# import datasets\n",
        "path = './'\n",
        "train_dataset = datasets.MNIST(path, train=True, download=True)\n",
        "test_dataset = datasets.MNIST(path, train=False, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdXJLMqShJrm",
        "outputId": "f10a1c14-2834-4402-e444-ebd2941ecb9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ml'...\n",
            "remote: Enumerating objects: 299, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 299 (delta 6), reused 3 (delta 3), pack-reused 289 (from 1)\u001b[K\n",
            "Receiving objects: 100% (299/299), 64.38 MiB | 42.56 MiB/s, done.\n",
            "Resolving deltas: 100% (155/155), done.\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train set\n",
        "X_train, y_train = train_dataset.data / 255, train_dataset.targets\n",
        "# test set\n",
        "X_test, y_test = test_dataset.data / 255, test_dataset.targets"
      ],
      "metadata": {
        "id": "PwGEJ7QyhOK8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check data\n",
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "print(\"X_test: \", X_test.shape)\n",
        "print(\"y_test: \", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8Vp-ZiQhTUk",
        "outputId": "fb790bf8-ae09-46d9-d15c-9d4b14cebbd1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  torch.Size([60000, 28, 28])\n",
            "y_train:  torch.Size([60000])\n",
            "X_test:  torch.Size([10000, 28, 28])\n",
            "y_test:  torch.Size([10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2d to 3d\n",
        "X_train, X_test = X_train.unsqueeze(1), X_test.unsqueeze(1)\n",
        "\n",
        "# check data\n",
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"X_test: \", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkFj0SDVhZCx",
        "outputId": "f120990b-c7fa-499a-9d0d-c1d136e4dd2d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  torch.Size([60000, 1, 28, 28])\n",
            "X_test:  torch.Size([10000, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make datasheet\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# make batch dataloader\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "k_K5z_Ichm_V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN model class\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden_layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=(3, 3)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
        "            nn.Dropout(0,5)\n",
        "        )\n",
        "\n",
        "        self.hidden_layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=(3, 3)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
        "            nn.Dropout(0,5)\n",
        "        )\n",
        "\n",
        "        self.hidden_layer3 = nn.Linear(128*5*5, 128)\n",
        "        self.output_layer = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.hidden_layer1(x)\n",
        "        out = self.hidden_layer2(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.hidden_layer3(out)\n",
        "        out = self.output_layer(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "_Ivweryuhufw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check model to GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# make CNN object\n",
        "model = CNN().to(device)\n",
        "\n",
        "# make CE loss model object\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# make Adam optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "zxlavmeLi6J9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define train model\n",
        "def train(model, criterion, optimizer, loader):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # batch train\n",
        "    for X_batch, y_batch in loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X_batch)\n",
        "        loss = criterion(hypothesis, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        y_predicted = torch.argmax(hypothesis, dim=1)\n",
        "        acc = (y_predicted == y_batch).float().mean()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(loader), epoch_acc / len(loader)"
      ],
      "metadata": {
        "id": "UNAqSIBCjE23"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define evaluation model\n",
        "def evaluate(model, criterion, loader):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            hypothesis = model(X_batch)\n",
        "            loss = criterion(hypothesis, y_batch)\n",
        "            y_predicted = torch.argmax(hypothesis, dim=1)\n",
        "            acc = (y_predicted == y_batch).float().mean()\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "        return epoch_loss / len(loader), epoch_acc / len(loader)"
      ],
      "metadata": {
        "id": "b_MwgPHHj27P"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "num_epochs = 20\n",
        "previous_train_loss, previous_train_acc = 1, 0\n",
        "previous_test_loss, previous_test_acc = 1, 0\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    current_train_loss, current_train_acc = train(model, criterion, optimizer, train_loader)\n",
        "    current_test_loss, current_test_acc = evaluate(model, criterion, test_loader)\n",
        "\n",
        "    print(f'epoch: {epoch}, train_loss: {current_train_loss:.4f}, train_acc: {current_train_acc:.4f}, test_loss: {current_test_loss:.4f}, test_acc: {current_test_acc:.4f} | {\"boolshit\" if current_train_acc + current_test_acc < previous_train_acc + previous_test_acc else \"awesome\"}')\n",
        "    previous_train_loss, previous_train_acc = current_train_loss, current_train_acc\n",
        "    previous_test_loss, previous_test_acc = current_test_loss, current_test_acc"
      ],
      "metadata": {
        "id": "QOX4WTRqkDb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bih7t88OkLzk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}